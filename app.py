# -*- coding: utf-8 -*-
# app.py: EMR AI - FIXED DOWNLOAD + REAL KERAS PREDICTION + NO SESSION CACHE
# CH·ªà HI·ªÇN TH·ªä THUMBNAIL 100x100 thay v√¨ full image + LO·∫†I B·ªé CACHE ƒê·ªÇ TR√ÅNH COOKIE QU√Å L·ªöN

import base64
import os
import io
import logging
import time
import requests
from PIL import Image
from flask import (
    Flask, flash, redirect, render_template, request, session, url_for
)
import pandas as pd
import gdown
import tensorflow as tf
import numpy as np
from tensorflow.keras.models import load_model, Sequential
from tensorflow.keras.layers import Dense, Input, Conv2D, Flatten

# ==========================================================
# KH·ªûI T·∫†O BI·∫æN TO√ÄN C·ª§C
# ==========================================================
MODEL = None
MODEL_LOADED = False
IS_DUMMY_MODE = False

# ==========================================================
# C·∫§U H√åNH MODEL
# ==========================================================
DRIVE_FILE_ID = "1ORV8tDkT03fxjRyaWU5liZ2bHQz3YQC"  # ‚ö†Ô∏è ID N√ÄY D·∫™N ƒê·∫æN 404 - FILE KH√îNG T·ªíN T·∫†I. THAY B·∫∞NG ID H·ª¢P L·ªÜ!
MODEL_FILE_NAME = "best_weights_model.keras"
MODEL_PATH = os.path.join(os.getcwd(), MODEL_FILE_NAME)
MODEL_INPUT_SIZE = (224, 224)  # K√≠ch th∆∞·ªõc input: 224x224
ALTERNATIVE_DOWNLOAD_URL = None  # V√≠ d·ª•: "https://your-direct-link.com/best_weights_model.keras" (n·∫øu c√≥)

# Thi·∫øt l·∫≠p logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# ==========================================================
# H√ÄM T·∫¢I FILE T·ª™ GOOGLE DRIVE HO·∫∂C URL THAY TH·∫æ
# ==========================================================
def download_file_from_gdrive(file_id, destination, max_retries=3):
    """
    T·∫£i file t·ª´ Google Drive ho·∫∑c URL thay th·∫ø v·ªõi retry v√† x√°c minh.
    Tr·∫£ v·ªÅ: (success: bool, is_dummy: bool).
    """
    if os.path.exists(destination):
        logger.info(f"File ƒë√£ t·ªìn t·∫°i: {destination}. ƒêang ki·ªÉm tra t√≠nh h·ª£p l·ªá...")
        try:
            temp_model = load_model(destination)
            temp_model.predict(np.zeros((1, MODEL_INPUT_SIZE[0], MODEL_INPUT_SIZE[1], 3)), verbose=0)
            logger.info("‚úÖ File t·ªìn t·∫°i l√† m√¥ h√¨nh Keras h·ª£p l·ªá.")
            return True, False
        except Exception as e:
            logger.warning(f"‚ùå File t·ªìn t·∫°i nh∆∞ng kh√¥ng h·ª£p l·ªá: {e}. X√≥a v√† t·∫£i l·∫°i...")
            os.remove(destination)

    gdrive_url = f"https://drive.google.com/uc?id={file_id}&export=download"
    logger.info(f"ƒêang c·ªë g·∫Øng t·∫£i model t·ª´ GDrive ID: {file_id}...")

    success = False
    for attempt in range(max_retries):
        try:
            head_resp = requests.head(gdrive_url, allow_redirects=True, timeout=10)
            logger.info(f"L·∫ßn th·ª≠ {attempt + 1}: HEAD URL {gdrive_url} -> Status {head_resp.status_code}")
            if head_resp.status_code != 200:
                raise Exception(f"Status code {head_resp.status_code}")

            gdown.download(id=file_id, output=destination, quiet=False, fuzzy=True)
            if os.path.exists(destination) and os.path.getsize(destination) > 0:
                temp_model = load_model(destination)
                temp_model.predict(np.zeros((1, MODEL_INPUT_SIZE[0], MODEL_INPUT_SIZE[1], 3)), verbose=0)
                logger.info("‚úÖ T·∫£i v√† x√°c minh m√¥ h√¨nh TH·ª∞C T·∫æ t·ª´ GDrive th√†nh c√¥ng.")
                return True, False
        except Exception as e:
            logger.error(f"‚ùå L·ªói GDrive l·∫ßn {attempt + 1}/{max_retries}: {e}")
            time.sleep(2 ** attempt)

    # Th·ª≠ URL thay th·∫ø n·∫øu c√≥
    if ALTERNATIVE_DOWNLOAD_URL:
        logger.info(f"Th·ª≠ t·∫£i t·ª´ URL thay th·∫ø: {ALTERNATIVE_DOWNLOAD_URL}")
        try:
            resp = requests.get(ALTERNATIVE_DOWNLOAD_URL, timeout=30)
            if resp.status_code == 200:
                with open(destination, 'wb') as f:
                    f.write(resp.content)
                temp_model = load_model(destination)
                temp_model.predict(np.zeros((1, MODEL_INPUT_SIZE[0], MODEL_INPUT_SIZE[1], 3)), verbose=0)
                logger.info("‚úÖ T·∫£i t·ª´ URL thay th·∫ø th√†nh c√¥ng.")
                return True, False
        except Exception as e:
            logger.error(f"‚ùå L·ªói t·∫£i t·ª´ URL thay th·∫ø: {e}")

    # T·∫°o dummy n·∫øu t·∫•t c·∫£ th·∫•t b·∫°i (ƒë·ªÉ app ch·∫°y, nh∆∞ng c·∫£nh b√°o)
    logger.warning("‚ö†Ô∏è T·∫•t c·∫£ t·∫£i xu·ªëng th·∫•t b·∫°i. T·∫°o DUMMY MODEL.")
    try:
        dummy_model = Sequential([
            Input(shape=(MODEL_INPUT_SIZE[0], MODEL_INPUT_SIZE[1], 3)),
            Conv2D(8, (3, 3), activation='relu'),
            Flatten(),
            Dense(1, activation='sigmoid')
        ])
        dummy_model.compile(optimizer='adam', loss='binary_crossentropy')
        dummy_model.save(destination)
        logger.info("‚úÖ Dummy model t·∫°o th√†nh c√¥ng.")
        return True, True
    except Exception as dummy_e:
        logger.error(f"‚ùå Kh√¥ng th·ªÉ t·∫°o dummy: {dummy_e}")
        return False, False

# ==========================================================
# T·∫¢I MODEL TO√ÄN C·ª§C
# ==========================================================
try:
    success, is_dummy = download_file_from_gdrive(DRIVE_FILE_ID, MODEL_PATH)
    if success:
        MODEL = load_model(MODEL_PATH)
        MODEL_LOADED = True
        IS_DUMMY_MODE = is_dummy
        logger.info("üöÄ Model t·∫£i th√†nh c√¥ng! DUMMY MODE: {}".format(IS_DUMMY_MODE))
    else:
        raise Exception("T·∫£i model th·∫•t b·∫°i ho√†n to√†n.")
except Exception as e:
    logger.error(f"‚ùå L·ªñI T·∫¢I MODEL: {e}. Ch·∫°y ·ªü FIXED MODE.")
    MODEL_LOADED = False
    IS_DUMMY_MODE = True  # FIXED = no prediction

# ==========================================================
# H√ÄM D·ª∞ ƒêO√ÅN
# ==========================================================
def img_to_array(img):
    return np.asarray(img)

def predict_image(img_bytes):
    if IS_DUMMY_MODE and MODEL_LOADED:
        prob_val = 0.5 + (np.random.rand() * 0.1 - 0.05)
        result = "Nodule (U)" if prob_val > 0.5 else "Non-nodule (Kh√¥ng U)"
        prob = prob_val if prob_val > 0.5 else 1.0 - prob_val
        return {
            "result": result,
            "probability": float(prob),
            "message": "DUMMY MODE: K·∫øt qu·∫£ m√¥ ph·ªèng (ID file GDrive kh√¥ng h·ª£p l·ªá - 404)."
        }

    if not MODEL_LOADED:
        return {"result": "L·ªñI H·ªÜ TH·ªêNG", "probability": 0.0, "message": "Model ch∆∞a t·∫£i (FIXED MODE). Ki·ªÉm tra file ID."}

    try:
        img = Image.open(io.BytesIO(img_bytes)).convert("RGB")
        img = img.resize(MODEL_INPUT_SIZE)
        img_array = img_to_array(img)
        img_array = np.expand_dims(img_array, axis=0) / 255.0
        prediction = MODEL.predict(img_array, verbose=0)[0][0]
        threshold = 0.5
        result = "Nodule (U)" if prediction >= threshold else "Non-nodule (Kh√¥ng U)"
        prob = float(prediction) if prediction >= threshold else float(1.0 - prediction)
        return {"result": result, "probability": prob, "message": "D·ª± ƒëo√°n b·∫±ng REAL MODEL."}
    except Exception as e:
        logger.error(f"Prediction error: {e}")
        return {"result": "L·ªñI", "probability": 0.0, "message": str(e)}

# ==========================================================
# FLASK APP
# ==========================================================
app = Flask(__name__)
app.secret_key = "emr-fixed-2025-no-crash"
app.config['MAX_CONTENT_LENGTH'] = 4 * 1024 * 1024
MAX_FILE_SIZE_MB = 4
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif', 'bmp'}

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def safe_image_to_b64(img_bytes, max_size=100):  # Gi·∫£m xu·ªëng 100x100 ~5-10KB
    try:
        with Image.open(io.BytesIO(img_bytes)) as img:
            img.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
            buffer = io.BytesIO()
            img.save(buffer, format='JPEG', quality=80, optimize=True)
            buffer.seek(0)
            return base64.b64encode(buffer.getvalue()).decode('utf-8')
    except Exception as e:
        logger.error(f"Thumbnail error: {e}")
        return None

# LO·∫†I B·ªé CACHE HO√ÄN TO√ÄN ƒê·ªÇ TR√ÅNH COOKIE QU√Å L·ªöN
# Lu√¥n t·∫°o thumbnail & predict m·ªõi m·ªói POST

@app.route("/", methods=["GET"])
def index():
    return render_template("index.html")

@app.route("/login", methods=["POST"])
def login():
    username = request.form.get("userID", "").strip()
    password = request.form.get("password", "").strip()
    if username == "user_demo" and password == "Test@123456":
        session['user'] = username
        return redirect(url_for("dashboard"))
    flash("Sai ID ho·∫∑c m·∫≠t kh·∫©u.", "danger")
    return redirect(url_for("index"))

@app.route("/dashboard")
def dashboard():
    if 'user' not in session:
        return redirect(url_for("index"))
    model_status = (
        "‚ùå FIXED MODE (KH√îNG C√ì MODEL - FILE ID 404)" if not MODEL_LOADED else
        "‚ö†Ô∏è DUMMY MODE (T·∫¢I TH·∫§T B·∫†I)" if IS_DUMMY_MODE else
        "‚úÖ REAL MODEL LOADED"
    )
    return render_template("dashboard.html", model_status=model_status)

@app.route("/emr_profile", methods=["GET", "POST"])
def emr_profile():
    if 'user' not in session:
        flash("Vui l√≤ng ƒëƒÉng nh·∫≠p.", "danger")
        return redirect(url_for("index"))
    # (Gi·ªØ nguy√™n code emr_profile c≈© - kh√¥ng thay ƒë·ªïi)
    # ... (copy t·ª´ code g·ªëc c·ªßa b·∫°n)

@app.route("/emr_prediction", methods=["GET", "POST"])
def emr_prediction():
    if 'user' not in session:
        return redirect(url_for("index"))
    
    prediction_result = None
    filename = None
    image_b64 = None

    if request.method == "POST":
        try:
            file = request.files.get('file')
            if not file or not file.filename:
                flash("‚ùå Ch∆∞a ch·ªçn file.", "danger")
                return render_template('emr_prediction.html')
            
            filename = file.filename
            if not allowed_file(filename):
                flash("‚ùå Ch·ªâ JPG/PNG/GIF/BMP", "danger")
                return render_template('emr_prediction.html')

            img_bytes = file.read()
            if len(img_bytes) > MAX_FILE_SIZE_MB * 1024 * 1024 or len(img_bytes) == 0:
                flash("‚ùå File k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá.", "danger")
                return render_template('emr_prediction.html')

            start_time = time.time()
            prediction_result = predict_image(img_bytes)
            image_b64 = safe_image_to_b64(img_bytes, max_size=100)
            logger.info(f"Prediction took {time.time() - start_time:.2f}s")
        except Exception as e:
            logger.error(f"POST error: {e}")
            flash("‚ùå L·ªói x·ª≠ l√Ω.", "danger")

    return render_template('emr_prediction.html', 
                           prediction=prediction_result, 
                           filename=filename, 
                           image_b64=image_b64,
                           model_loaded=MODEL_LOADED)

@app.route("/logout")
def logout():
    session.clear()
    return redirect(url_for("index"))

@app.route("/health")
def health():
    return {"status": "healthy"}, 200

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    status = "FIXED (NO MODEL)" if not MODEL_LOADED else "DUMMY" if IS_DUMMY_MODE else "REAL"
    logger.info(f"üöÄ EMR AI - MODE: {status} (FILE ID 404 - C·∫¶N S·ª¨A)")
    app.run(host="0.0.0.0", port=port, debug=False, threaded=True)
