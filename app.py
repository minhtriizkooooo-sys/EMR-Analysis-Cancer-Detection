# -*- coding: utf-8 -*-
# app.py: EMR AI - FINAL OPTIMIZATION FOR RENDER STABILITY
import os
import io
import base64
import logging
import tempfile
import numpy as np
import pandas as pd
import requests
from flask import (
    Flask, flash, redirect, render_template, request, session, url_for
)
from werkzeug.utils import secure_filename
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from PIL import Image
from functools import wraps
from ydata_profiling import ProfileReport

# === LOGGING ===
# Thi·∫øt l·∫≠p logging c∆° b·∫£n ƒë·ªÉ d·ªÖ d√†ng theo d√µi tr√™n Render logs
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# === FLASK SETUP ===
app = Flask(__name__)
# ƒê·∫£m b·∫£o secret key ƒë∆∞·ª£c ƒë·∫∑t
app.secret_key = os.environ.get("FLASK_SECRET_KEY", "emr-secure-2025")
app.config['MAX_CONTENT_LENGTH'] = 10 * 1024 * 1024  # TƒÉng l√™n 10MB cho file data
MAX_FILE_SIZE_MB = 10
ALLOWED_IMG_EXT = {'png', 'jpg', 'jpeg', 'bmp'}
ALLOWED_DATA_EXT = {'csv', 'xls', 'xlsx'}

# === MODEL PATH ===
MODEL_FOLDER = "models"
os.makedirs(MODEL_FOLDER, exist_ok=True)
MODEL_PATH = os.path.join(MODEL_FOLDER, "best_weights_model.keras")
HF_MODEL_URL = "https://huggingface.co/spaces/minhtriizkooooo/EMR-Analysis-Cancer-Detection/resolve/main/models/best_weights_model.keras"

# === LOAD MODEL ONCE (Eager Loading) ===
model = None
try:
    if not os.path.exists(MODEL_PATH):
        logger.info("Downloading model from HF...")
        r = requests.get(HF_MODEL_URL, stream=True, timeout=180) # TƒÉng timeout cho download
        r.raise_for_status()
        with open(MODEL_PATH, "wb") as f:
            for chunk in r.iter_content(8192):
                f.write(chunk)
        logger.info("Model downloaded.")
    else:
        logger.info("Model found locally.")

    model = load_model(MODEL_PATH)
    logger.info("‚úÖ REAL KERAS MODEL LOADED SUCCESSFULLY")
except Exception as e:
    logger.error(f"‚ùå Model load failed during startup: {e}")
    # ƒê·∫∑t model l√† None n·∫øu t·∫£i th·∫•t b·∫°i, c√°c route d·ª± ƒëo√°n s·∫Ω ki·ªÉm tra bi·∫øn n√†y
    model = None

# === UTILS ===
def allowed_file(filename, exts):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in exts

def safe_thumbnail(img_bytes, size=200):
    """T·∫°o thumbnail an to√†n cho ·∫£nh hi·ªÉn th·ªã"""
    try:
        img = Image.open(io.BytesIO(img_bytes))
        img.thumbnail((size, size), Image.Resampling.LANCZOS)
        buf = io.BytesIO()
        img.save(buf, 'JPEG', quality=85)
        return base64.b64encode(buf.getvalue()).decode()
    except Exception as e:
        logger.error(f"Thumbnail generation error: {e}")
        return None

def login_required(f):
    @wraps(f)
    def wrap(*args, **kwargs):
        if 'user' not in session: return redirect(url_for('login'))
        return f(*args, **kwargs)
    return wrap

# === ROUTES ===
@app.route("/")
def home(): return redirect(url_for("login"))

@app.route("/login", methods=["GET", "POST"])
def login():
    if request.method == "POST":
        if request.form.get("userID") == "user_demo" and request.form.get("password") == "Test@123456":
            session['user'] = "user_demo"
            return redirect(url_for("dashboard"))
        flash("Sai ID ho·∫∑c m·∫≠t kh·∫©u.", "danger")
    return render_template("index.html")

@app.route("/dashboard")
@login_required
def dashboard():
    status = "Model ƒê√£ S·∫µn S√†ng" if model else "Model Ch∆∞a T·∫£i ƒê∆∞·ª£c"
    return render_template("dashboard.html", model_status=status)

@app.route("/logout")
def logout():
    session.clear()
    flash("ƒê√£ ƒëƒÉng xu·∫•t.", "info")
    return redirect(url_for("login"))

@app.route("/health")
def health():
    """Route ƒë∆°n gi·∫£n ƒë·ªÉ Render/Gunicorn ki·ªÉm tra tr·∫°ng th√°i ·ª©ng d·ª•ng"""
    return {"status": "ok", "model_loaded": model is not None}, 200

# === EMR PROFILE: S·ª¨A L·ªñI LOGIC V√Ä T·ªêI ∆ØU H√ìA T·ªêC ƒê·ªò ===
@app.route("/emr_profile", methods=["GET", "POST"])
@login_required
def emr_profile():
    profile_html = None
    filename = None

    if request.method == "POST":
        file = request.files.get("file")
        if not file or not file.filename:
            flash("Vui l√≤ng ch·ªçn file.", "danger")
            return render_template("emr_profile.html")

        filename = secure_filename(file.filename)
        if not allowed_file(filename, ALLOWED_DATA_EXT):
            flash("Ch·ªâ h·ªó tr·ª£ CSV, XLS, XLSX.", "danger")
            return render_template("emr_profile.html")

        try:
            # ƒê·ªçc bytes t·ª´ file (tr√°nh l∆∞u file l·ªõn)
            file_bytes = file.read()
            if len(file_bytes) > MAX_FILE_SIZE_MB * 1024 * 1024:
                flash(f"File qu√° l·ªõn (> {MAX_FILE_SIZE_MB}MB).", "danger")
                return render_template("emr_profile.html")

            stream = io.BytesIO(file_bytes)
            # Ki·ªÉm tra ƒëu√¥i file ƒë·ªÉ ƒë·ªçc ƒë√∫ng ƒë·ªãnh d·∫°ng
            if filename.lower().endswith('.csv'):
                df = pd.read_csv(stream)
            else:
                df = pd.read_excel(stream)

            # === T·ªêI ∆ØU H√ìA: PROFILE NHANH V√Ä NH·∫∏ ===
            # N·∫øu DataFrame l·ªõn h∆°n 2000 h√†ng, ch·ªâ l·∫•y m·∫´u ƒë·ªÉ tr√°nh crash worker do OOM/Timeout
            if len(df) > 2000:
                df_size = len(df)
                df = df.sample(2000, random_state=42)
                flash(f"File c√≥ {df_size} d√≤ng. ƒêang ph√¢n t√≠ch m·∫´u 2000 d√≤ng ƒë·ªÉ tr√°nh Timeout.", "warning")

            # S·ª≠ d·ª•ng minimal=True ƒë·ªÉ ƒë·∫°t t·ªëc ƒë·ªô nhanh nh·∫•t (Fast and Light)
            flash("üïí ƒêang t·∫°o b√°o c√°o chuy√™n s√¢u (ch·∫ø ƒë·ªô T·ªêC ƒê·ªò CAO). Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t ƒë·∫øn 1-2 ph√∫t t√πy k√≠ch th∆∞·ªõc file.", "info")
            profile = ProfileReport(
                df,
                title=f"Ph√¢n t√≠ch D·ªØ li·ªáu EMR: {filename}",
                minimal=True,  # CH·∫æ ƒê·ªò NHANH NH·∫§T: KH·∫ÆC PH·ª§C L·ªñI LOGIC V√Ä TƒÇNG T·ªêC
                html={"style": {"full_width": True}}
            )
            profile_html = profile.to_html()
            flash("‚úÖ B√°o c√°o chuy√™n s√¢u ho√†n th√†nh!", "success")

        except Exception as e:
            logger.error(f"Profile error: {e}")
            # Th√¥ng b√°o l·ªói chung, khuy·∫øn kh√≠ch d√πng file nh·ªè h∆°n
            flash(f"‚ùå L·ªói x·ª≠ l√Ω d·ªØ li·ªáu: {str(e)}. Vui l√≤ng ki·ªÉm tra ƒë·ªãnh d·∫°ng file (header, encoding) ho·∫∑c d√πng file nh·ªè h∆°n.", "danger")

    return render_template("emr_profile.html", profile_html=profile_html, filename=filename)

# === EMR PREDICTION: S·ª¨ D·ª§NG MODEL ƒê√É LOAD S·∫¥N ===
@app.route("/emr_prediction", methods=["GET", "POST"])
@login_required
def emr_prediction():
    prediction = None
    filename = None
    image_b64 = None

    if request.method == "POST":
        if model is None:
            flash("‚ùå L·ªói d·ª± ƒëo√°n: Model ch∆∞a t·∫£i ƒë∆∞·ª£c khi kh·ªüi ƒë·ªông. Ki·ªÉm tra logs.", "danger")
            return render_template("emr_prediction.html")

        file = request.files.get("file")
        if not file or not file.filename:
            flash("Vui l√≤ng ch·ªçn ·∫£nh.", "danger")
            return render_template("emr_prediction.html")

        filename = secure_filename(file.filename)
        if not allowed_file(filename, ALLOWED_IMG_EXT):
            flash("Ch·ªâ h·ªó tr·ª£ JPG, PNG, BMP.", "danger")
            return render_template("emr_prediction.html")

        # ƒê·ªçc bytes, ki·ªÉm tra k√≠ch th∆∞·ªõc
        img_bytes = file.read()
        if len(img_bytes) > MAX_FILE_SIZE_MB * 1024 * 1024:
            flash(f"·∫¢nh >{MAX_FILE_SIZE_MB}MB.", "danger")
            return render_template("emr_prediction.html")

        # Thumbnail
        image_b64 = safe_thumbnail(img_bytes)

        # Predict REAL MODEL
        tmp_path = None
        try:
            # S·ª≠ d·ª•ng file t·∫°m th·ªùi ƒë·ªÉ Keras/PIL c√≥ th·ªÉ ƒë·ªçc file
            with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(filename)[1]) as tmp:
                tmp.write(img_bytes)
                tmp_path = tmp.name

            img = load_img(tmp_path, target_size=(240, 240))
            arr = img_to_array(img) / 255.0
            arr = np.expand_dims(arr, axis=0)

            # D·ª∞ ƒêO√ÅN TH·∫¨T ‚Äì C·ª∞C NHANH
            prob = float(model.predict(arr, verbose=0)[0][0])
            result = "Nodule (C√≥ kh·ªëi u)" if prob > 0.5 else "Non-nodule (Kh√¥ng c√≥ kh·ªëi u)"
            prediction = {"result": result, "probability": prob}

            flash(f"AI: {result} ({prob*100:.1f}%)", "success")

        except Exception as e:
            logger.error(f"Predict error: {e}")
            flash(f"‚ùå L·ªói AI: {e}", "danger")
        finally:
            # ƒê·∫£m b·∫£o x√≥a file t·∫°m
            if tmp_path and os.path.exists(tmp_path):
                os.remove(tmp_path)

    return render_template(
        "emr_prediction.html",
        prediction=prediction,
        filename=filename,
        image_b64=image_b64
    )

# === RUN ===
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    logger.info(f"EMR AI starting on port {port}")
    app.run(host="0.0.0.0", port=port, debug=False, threaded=False) # T·∫Øt threaded cho Render/Gunicorn
```
eof

### ‚ö†Ô∏è B∆Ø·ªöC CU·ªêI C√ôNG ƒê·ªÇ KH·∫ÆC PH·ª§C L·ªñI 502

B·∫°n **ph·∫£i** ƒë·∫£m b·∫£o r·∫±ng d·ªãch v·ª• Render c·ªßa b·∫°n c√≥ ƒë·ªß th·ªùi gian ƒë·ªÉ x·ª≠ l√Ω t√°c v·ª• t·∫°o b√°o c√°o (t·ªëi ƒëa 2 ph√∫t).

H√£y ki·ªÉm tra l·∫°i **Start Command** trong Render Settings v√† ƒë·∫∑t n√≥ nh∆∞ sau:

```bash
gunicorn app:app --timeout 120
